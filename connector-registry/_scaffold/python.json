{
  "$schema": "https://schemas.connector-factory.dev/scaffold.schema.json",
  "scaffold": "python",
  "version": "0.2.0",
  "description": "Python implementation scaffold for a connector. Places a Python package under connector/version/author/python/{implementation} with conventional src/tests layout and minimal templates.",
  "variables": {
    "connector": {
      "description": "Connector name (kebab-case).",
      "example": "stripe",
      "pattern": "^[a-z0-9][a-z0-9-]*$"
    },
    "version": {
      "description": "Source version identifier (not necessarily semver). Examples: v4, ga4, 2020-08-27, api-2020.08.27",
      "example": "v4",
      "pattern": "^[A-Za-z0-9][A-Za-z0-9._-]*$"
    },
    "author": {
      "description": "GitHub organization or user handle (kebab-case). Used for linking and avatars.",
      "example": "514-labs",
      "pattern": "^[a-z0-9](?:[a-z0-9-]{0,37}[a-z0-9])?$"
    },
    "implementation": {
      "description": "Implementation name nested under the language folder (kebab-case). Defaults to 'default'.",
      "example": "default",
      "pattern": "^[a-z0-9][a-z0-9-]*$",
      "default": "default"
    },
    "packageName": {
      "description": "Python package name (snake_case).",
      "example": "connector_stripe",
      "pattern": "^[a-z_][a-z0-9_]*$"
    },
    "resource": {
      "description": "Default REST resource path segment (kebab-case).",
      "example": "contacts",
      "pattern": "^[a-z0-9][a-z0-9-]*$",
      "default": "resource"
    }
  },
  "structure": [
    {
      "type": "dir",
      "name": "{connector}",
      "children": [
        {
          "type": "dir",
          "name": "{version}",
          "children": [
            {
              "type": "dir",
              "name": "{author}",
              "children": [
                {
                  "type": "dir",
                  "name": "python",
                  "children": [
                    {
                      "type": "dir",
                      "name": "{implementation}",
                      "children": [
                        {
                          "type": "file",
                          "name": ".gitignore",
                          "template": "__pycache__/\n.venv/\n.env\n.dist/\n"
                        },
                        {
                          "type": "file",
                          "name": ".env.example",
                          "template": "API_KEY=\n"
                        },
                        {
                          "type": "file",
                          "name": "README.md",
                          "template": "# {connector} (Python)\n\nPython implementation for `{connector}` by `{author}`.\n\n"
                        },
                        {
                          "type": "file",
                          "name": "pyproject.toml",
                          "template": "[project]\nname = \"{packageName}\"\nversion = \"0.1.0\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nlicense = {text = \"MIT\"}\nauthors = [ { name = \"{author}\" } ]\ndependencies = [ ]\n\n[tool.ruff]\nline-length = 100\n\n[build-system]\nrequires = [\"setuptools>=68\",\"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n"
                        },
                        {
                          "type": "dir",
                          "name": "docs",
                          "children": [
                            {
                              "type": "file",
                              "name": "getting-started.md",
                              "template": "# Getting started\n\nThis is a placeholder. Document how to configure and run the connector in Python.\n"
                            },
                            {
                              "type": "file",
                              "name": "configuration.md",
                              "template": "# Configuration\n\nDocument configuration options (auth, scopes, IDs).\n"
                            },
                            {
                              "type": "file",
                              "name": "schema.md",
                              "template": "# Schema\n\nRefer to `schemas/index.json` and related files.\n\n## Organization\n\nSchemas support nested folder structures for better organization:\n\n- **raw/** - Raw API schemas\n  - `endpoints/` - API endpoint request/response schemas\n  - `types/` - Shared type definitions for endpoints (not shown as Files)\n  - `events/` - Event payloads\n- **extracted/** - Normalized schemas\n  - `entities/` - Business entities\n  - `metrics/` - Aggregated data\n- **files/** - File-based schemas (CSV/JSON/Parquet/Avro/NDJSON). Only items under `schemas/files` appear in the Files tab.\n\n## Adding Schemas\n\n1. Create schema files in appropriate nested folders\n2. Update `schemas/index.json` with correct paths for endpoints and tables\n3. Place file schemas under `schemas/files` (no index entries needed)\n"
                            },
                            {
                              "type": "file",
                              "name": "limits.md",
                              "template": "# Limits\n\nDescribe API limits, quotas, and rate limiting behavior.\n"
                            }
                          ]
                        },
                        {
                          "type": "dir",
                          "name": "schemas",
                          "children": [
                            {
                              "type": "file",
                              "name": "index.json",
                              "template": "{\n  \"$schema\": \"https://schemas.connector-factory.dev/schema-index.schema.json\",\n  \"version\": \"0.1.0\",\n  \"datasets\": [\n    {\n      \"name\": \"events\",\n      \"stage\": \"raw\",\n      \"kind\": \"endpoints\",\n      \"path\": \"raw/endpoints/events.schema.json\",\n      \"doc\": \"raw/endpoints/events.md\"\n    },\n    {\n      \"name\": \"events\",\n      \"stage\": \"extracted\",\n      \"kind\": \"endpoints\",\n      \"path\": \"extracted/endpoints/events.schema.json\",\n      \"doc\": \"extracted/endpoints/events.md\"\n    }\n  ],\n  \"_examples\": {\n    \"_comment\": \"Below are examples of how to use nested folders. Copy and modify these patterns:\",\n    \"endpoint_example\": {\n      \"name\": \"users.create\",\n      \"stage\": \"raw\",\n      \"kind\": \"endpoints\",\n      \"path\": \"raw/endpoints/endpoints/users/create.schema.json\",\n      \"doc\": \"raw/endpoints/endpoints/users/create.md\",\n      \"metadata\": {\n        \"category\": \"endpoint\",\n        \"apiMethod\": \"POST\"\n      }\n    },\n    \"nested_organization_example\": {\n      \"name\": \"reports.analytics\",\n      \"stage\": \"raw\",\n      \"kind\": \"endpoints\",\n      \"path\": \"raw/endpoints/endpoints/reports/analytics.schema.json\",\n      \"doc\": \"raw/endpoints/endpoints/reports/analytics.md\"\n    }\n  }\n}\n"
                            },
                            {
                              "type": "dir",
                              "name": "raw",
                              "children": [
                                {
                                  "type": "dir",
                                  "name": "json",
                                  "children": [
                                    {
                                      "type": "file",
                                      "name": "README.md",
                                      "template": "# Raw JSON Schemas\n\nThis directory contains raw JSON schemas from the source API.\n\n## Organization\n\nSchemas can be organized in nested folders for better structure:\n- `endpoints/` - API endpoint request/response schemas\n- `types/` - Shared type definitions\n- `events/` - Event or webhook payloads\n- Or any logical grouping that makes sense for your connector\n\n## Example Structure\n\n```\njson/\n├── endpoints/\n│   ├── users.schema.json\n│   └── users.md\n├── types/\n│   ├── User.schema.json\n│   └── User.md\n└── events.schema.json\n```\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "events.schema.json",
                                      "template": "{\\n  \\\"$schema\\\": \\\"http://json-schema.org/draft-07/schema#\\\",\\n  \\\"title\\\": \\\"Raw Event\\\",\\n  \\\"type\\\": \\\"object\\\",\\n  \\\"additionalProperties\\\": true\\n}\\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "events.md",
                                      "template": "# Raw events (JSON)\n\nDescribe the upstream event payload.\n"
                                    }
                                  ]
                                },
                                {
                                  "type": "dir",
                                  "name": "files",
                                  "children": [
                                    {
                                      "type": "file",
                                      "name": "README.md",
                                      "template": "# File schemas\n\nPlace file-based schemas here (CSV/JSON/Parquet/Avro/NDJSON). Files in this folder are shown in the Files tab.\n\nExamples:\n- `events.csv`\n- `events.schema.json` (with title/description)\n"
                                    }
                                  ]
                                },
                                {
                                  "type": "dir",
                                  "name": "relational",
                                  "children": [
                                    {
                                      "type": "file",
                                      "name": "tables.json",
                                      "template": "{\\n  \\\"tables\\\": []\\n}\\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "tables.sql",
                                      "template": "-- DDL placeholders for raw tables\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "README.md",
                                      "template": "# Raw relational schema\n\nDescribe tables and relationships.\n"
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "type": "dir",
                              "name": "extracted",
                              "children": [
                                {
                                  "type": "dir",
                                  "name": "json",
                                  "children": [
                                    {
                                      "type": "file",
                                      "name": "README.md",
                                      "template": "# Extracted JSON Schemas\n\nThis directory contains normalized/transformed JSON schemas.\n\n## Organization\n\nLike raw schemas, extracted schemas can be organized in nested folders:\n- `entities/` - Normalized business entities\n- `metrics/` - Calculated metrics or aggregations\n- `reports/` - Structured report schemas\n- Or any logical grouping for your transformed data\n\n## Naming Convention\n\nUse the same folder structure as in `raw/endpoints/` when there's a 1:1 mapping, or create new logical groupings for transformed data.\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "events.schema.json",
                                      "template": "{\\n  \\\"$schema\\\": \\\"http://json-schema.org/draft-07/schema#\\\",\\n  \\\"title\\\": \\\"Extracted Event\\\",\\n  \\\"type\\\": \\\"object\\\",\\n  \\\"additionalProperties\\\": false,\\n  \\\"properties\\\": {}\\n}\\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "events.md",
                                      "template": "# Extracted events (JSON)\n\nDescribe the normalized event shape.\n"
                                    }
                                  ]
                                },
                                {
                                  "type": "dir",
                                  "name": "relational",
                                  "children": [
                                    {
                                      "type": "file",
                                      "name": "tables.json",
                                      "template": "{\\n  \\\"tables\\\": []\\n}\\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "tables.sql",
                                      "template": "-- DDL placeholders for extracted tables\n"
                                    },
                                    {
                                      "type": "file",
                                      "name": "README.md",
                                      "template": "# Extracted relational schema\n\nDescribe normalized tables and relationships.\n"
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "type": "dir",
                          "name": "src",
                          "children": [
                            {
                              "type": "dir",
                              "name": "lib",
                              "children": [
                                { "type": "file", "name": "__init__.py" },
                                {
                                  "type": "file",
                                  "name": "paginate.py",
                                  "template": "from typing import Any, Callable, Dict, Generator, Optional, TypedDict\n\nclass HttpResponseEnvelope(TypedDict):\n    data: Any\n\nSendFn = Callable[[Dict[str, Any]], HttpResponseEnvelope]\n\ndef paginate_cursor(\n    *,\n    send: Callable[[Dict[str, Any]], HttpResponseEnvelope],\n    path: str,\n    query: Optional[Dict[str, Any]] = None,\n    page_size: Optional[int] = None,\n    extract_items = None,\n    extract_next_cursor = None,\n) -> Generator[list[Any], None, None]:\n    if extract_items is None:\n        extract_items = lambda res: res.get('results', [])\n    if extract_next_cursor is None:\n        extract_next_cursor = lambda res: (res.get('paging', {}).get('next', {}) or {}).get('after')\n\n    after = (query or {}).get('after') if query else None\n    limit = page_size or (query or {}).get('limit') or 100\n    while True:\n        res = send({ 'method': 'GET', 'path': path, 'query': { **(query or {}), 'limit': limit, 'after': after }, 'operation': 'paginate' })\n        items = extract_items(res['data'])\n        yield items\n        next_cur = extract_next_cursor(res['data'])\n        if not next_cur:\n            break\n        after = next_cur\n"
                                },
                                {
                                  "type": "file",
                                  "name": "make_resource.py",
                                  "template": "from .paginate import paginate_cursor\nfrom typing import Any, Dict, Optional\n\n# Create a CRUD surface for a REST resource at `object_path`.\n\ndef make_crud_resource(object_path: str, send):\n    def list_(properties: Optional[list[str]] = None, limit: Optional[int] = None, after: Optional[str] = None):\n        query: Dict[str, Any] = {}\n        if properties:\n            query['properties'] = ','.join(properties)\n        if limit is not None:\n            query['limit'] = limit\n        if after is not None:\n            query['after'] = after\n        return send({ 'method': 'GET', 'path': object_path, 'query': query })\n\n    def get(id: str, properties: Optional[list[str]] = None):\n        query: Dict[str, Any] = {}\n        if properties:\n            query['properties'] = ','.join(properties)\n        return send({ 'method': 'GET', 'path': f\"{object_path}/{id}\", 'query': query })\n\n    def stream_all(properties: Optional[list[str]] = None, page_size: Optional[int] = None):\n        query: Dict[str, Any] = {}\n        if properties:\n            query['properties'] = ','.join(properties)\n        for items in paginate_cursor(send=send, path=object_path, query=query, page_size=page_size):\n            for item in items:\n                yield item\n\n    def get_all(properties: Optional[list[str]] = None, page_size: Optional[int] = None, max_items: Optional[int] = None):\n        results: list[Any] = []\n        for item in stream_all(properties=properties, page_size=page_size):\n            results.append(item)\n            if max_items is not None and len(results) >= max_items:\n                break\n        return results\n\n    return { 'list': list_, 'get': get, 'stream_all': stream_all, 'get_all': get_all }\n"
                                },
                                {
                                  "type": "file",
                                  "name": "hooks.py",
                                  "template": "from typing import Any, Callable, Dict, List, Optional, TypedDict\n\nclass RequestOptions(TypedDict, total=False):\n    method: str\n    path: str\n    query: Dict[str, Any]\n    headers: Dict[str, str]\n    body: Any\n    timeout_ms: int\n    operation: str\n\nclass ResponseMeta(TypedDict, total=False):\n    timestamp: int\n    duration_ms: int\n    retry_count: int\n    request_id: str\n\nclass ResponseEnvelope(TypedDict, total=False):\n    data: Any\n    status: int\n    headers: Dict[str, str]\n    meta: ResponseMeta\n\nclass HookContext(TypedDict, total=False):\n    type: str\n    request: RequestOptions\n    response: ResponseEnvelope\n    error: Any\n    metadata: Dict[str, Any]\n    attempt: int\n\nHook = Callable[[HookContext], None]\n\nclass Hooks(TypedDict, total=False):\n    beforeRequest: List[Hook]\n    afterResponse: List[Hook]\n    onError: List[Hook]\n    onRetry: List[Hook]\n\nasync def run_hooks(hooks: Optional[List[Hook]], ctx: HookContext) -> None:\n    if not hooks:\n        return\n    for hook in hooks:\n        res = hook(ctx)\n        if hasattr(res, '__await__'):\n            await res  # type: ignore\n"
                                },
                                {
                                  "type": "file",
                                  "name": "send.py",
                                  "template": "import asyncio\nimport random\nimport time\nfrom typing import Any, Callable, Dict, Optional\n\nfrom .hooks import Hooks, RequestOptions, ResponseEnvelope, run_hooks\n\nDoRequest = Callable[[RequestOptions], ResponseEnvelope]\n\nclass RetryConfig:\n    def __init__(self, max_attempts: int = 3, initial_delay_ms: int = 1000, max_delay_ms: int = 30000, backoff_multiplier: float = 2.0, retryable_status_codes: Optional[list[int]] = None, respect_retry_after: bool = True):\n        self.max_attempts = max_attempts\n        self.initial_delay_ms = initial_delay_ms\n        self.max_delay_ms = max_delay_ms\n        self.backoff_multiplier = backoff_multiplier\n        self.retryable_status_codes = retryable_status_codes or [408, 425, 429, 500, 502, 503, 504]\n        self.respect_retry_after = respect_retry_after\n\n    def calc_delay(self, attempt: int) -> int:\n        exp = self.initial_delay_ms * (self.backoff_multiplier ** (attempt - 1))\n        bounded = min(exp, self.max_delay_ms)\n        jitter = bounded * (0.5 + random.random() * 0.5)\n        return int(jitter)\n\nasync def create_send(do_request: DoRequest, hooks: Optional[Hooks] = None, retry: Optional[RetryConfig] = None):\n    retry_cfg = retry or RetryConfig()\n\n    async def send(req: RequestOptions) -> ResponseEnvelope:\n        started_at = int(time.time() * 1000)\n        last_error: Any = None\n        for attempt in range(1, retry_cfg.max_attempts + 1):\n            try:\n                await run_hooks((hooks or {}).get('beforeRequest'), { 'type': 'beforeRequest', 'request': req, 'attempt': attempt })\n                res = do_request(req)\n                await run_hooks((hooks or {}).get('afterResponse'), { 'type': 'afterResponse', 'request': req, 'response': res, 'attempt': attempt })\n                status = res.get('status', 200)\n                if status not in retry_cfg.retryable_status_codes:\n                    meta = res.get('meta', {})\n                    meta.update({ 'timestamp': int(time.time() * 1000), 'duration_ms': int(time.time() * 1000) - started_at, 'retry_count': attempt - 1 })\n                    res['meta'] = meta\n                    return res\n                last_error = Exception(f'Retryable status: {status}')\n            except Exception as err:\n                last_error = err\n                await run_hooks((hooks or {}).get('onError'), { 'type': 'onError', 'request': req, 'error': err, 'attempt': attempt })\n            if attempt < retry_cfg.max_attempts:\n                await run_hooks((hooks or {}).get('onRetry'), { 'type': 'onRetry', 'request': req, 'error': last_error, 'attempt': attempt })\n                await asyncio.sleep(retry_cfg.calc_delay(attempt) / 1000.0)\n                continue\n            break\n        raise last_error or Exception('Request failed')\n\n    return send\n"
                                }
                              ]
                            },
                            {
                              "type": "dir",
                              "name": "{resource}",
                              "children": [
                                {
                                  "type": "file",
                                  "name": "__init__.py",
                                  "template": "from ..lib.make_resource import make_crud_resource\n\n__all__ = ['create_resource']\n\n\ndef create_resource(send):\n    return make_crud_resource('/{resource}', send)\n"
                                },
                                {
                                  "type": "file",
                                  "name": "model.py",
                                  "template": "from typing import Any, TypedDict\n\nclass Model(TypedDict, total=False):\n    # Define your resource model fields\n    any_field: Any\n"
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "type": "dir",
                          "name": "scripts",
                          "children": [
                            {
                              "type": "file",
                              "name": "_shared.py",
                              "template": "import json\nimport os\nimport sys\nfrom typing import Any, Dict\nfrom ..src.lib.send import create_send\n\nclass HttpError(Exception):\n    pass\n\ntry:\n    import urllib.request as urllib_request\n    import urllib.parse as urllib_parse\nexcept Exception:  # pragma: no cover\n    urllib_request = None  # type: ignore\n    urllib_parse = None  # type: ignore\n\n\ndef get_env(key: str, fallback: str | None = None) -> str:\n    val = os.getenv(key)\n    if val is None or val == '':\n        if fallback is not None:\n            return fallback\n        raise RuntimeError('Missing required env var: ' + key)\n    return val\n\n\ndef make_do_request(base_url: str, default_headers: Dict[str,str] | None = None):\n    default_headers = default_headers or {}\n\n    def do_request(req: Dict[str, Any]):\n        method = req.get('method', 'GET')\n        path = req.get('path', '')\n        query = req.get('query') or {}\n        url = path if path.startswith('http') else f'{base_url}{path}'\n        if query:\n            qs = urllib_parse.urlencode({ k: v for k, v in query.items() if v is not None })\n            if qs:\n                url = f'{url}?{qs}'\n        headers = { 'content-type': 'application/json', **default_headers, **(req.get('headers') or {}) }\n        data = None\n        if req.get('body') is not None:\n            data = json.dumps(req['body']).encode('utf-8')\n        request = urllib_request.Request(url=url, data=data, method=method, headers=headers)\n        with urllib_request.urlopen(request) as resp:  # nosec B310\n            status = resp.status\n            body = resp.read()\n            try:\n                payload = json.loads(body.decode('utf-8'))\n            except Exception:\n                payload = {}\n            return { 'data': payload, 'status': status, 'headers': dict(resp.headers) }\n\n    return do_request\n\n\ndef create_resource_and_send():\n    base_url = get_env('BASE_URL', 'https://api.example.com')\n    api_key = os.getenv('API_KEY')\n    headers: Dict[str,str] = {}\n    if api_key:\n        headers['Authorization'] = f'Bearer {api_key}'\n    do_request = make_do_request(base_url, headers)\n    send = (awaitable_send := create_send(do_request))  # type: ignore\n    # create_send returns a coroutine in our template; resolve synchronously for scripts\n    import asyncio\n    if hasattr(awaitable_send, '__await__'):\n        send = asyncio.get_event_loop().run_until_complete(awaitable_send)  # type: ignore\n    from ..src.{resource} import create_resource as create_resource_impl\n    resource = create_resource_impl(send)\n    return send, resource\n"
                            },
                            {
                              "type": "file",
                              "name": "auth_check.py",
                              "template": "import json\nfrom ._shared import create_resource_and_send\n\ndef main():\n    _, resource = create_resource_and_send()\n    try:\n        res = resource['list'](limit=1)\n        print(json.dumps({ 'ok': True, 'sampleCount': len((res.get('data', {}) or {}).get('results', []) ) }))\n    except Exception as err:\n        print(json.dumps({ 'ok': False, 'error': str(err) }))\n        raise SystemExit(1)\n\nif __name__ == '__main__':\n    main()\n"
                            },
                            {
                              "type": "file",
                              "name": "list.py",
                              "template": "import argparse, json\nfrom ._shared import create_resource_and_send\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--limit', type=int)\nparser.add_argument('--after')\nparser.add_argument('--properties')\n\nargs = parser.parse_args()\n\n_, resource = create_resource_and_send()\nparams = {}\nif args.limit is not None: params['limit'] = args.limit\nif args.after is not None: params['after'] = args.after\nif args.properties: params['properties'] = args.properties.split(',')\nres = resource['list'](**params)\nprint(json.dumps(res.get('data', {})))\n"
                            },
                            {
                              "type": "file",
                              "name": "get.py",
                              "template": "import argparse, json, sys\nfrom ._shared import create_resource_and_send\n\nparser = argparse.ArgumentParser()\nparser.add_argument('id')\nparser.add_argument('--properties')\nargs = parser.parse_args()\n\n_, resource = create_resource_and_send()\nparams = { 'id': args.id }\nif args.properties: params['properties'] = args.properties.split(',')\nres = resource['get'](**params)\nprint(json.dumps(res.get('data', {})))\n"
                            },
                            {
                              "type": "file",
                              "name": "stream_all.py",
                              "template": "import argparse, json, sys\nfrom ._shared import create_resource_and_send\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--page-size', type=int, dest='page_size')\nparser.add_argument('--properties')\nargs = parser.parse_args()\n\n_, resource = create_resource_and_send()\nparams = {}\nif args.page_size is not None: params['page_size'] = args.page_size\nif args.properties: params['properties'] = args.properties.split(',')\ncount = 0\nfor item in resource['stream_all'](**params):\n    print(json.dumps(item))\n    count += 1\nprint(json.dumps({ 'rows_read': count }))\n"
                            },
                            {
                              "type": "file",
                              "name": "get_all.py",
                              "template": "import argparse, json\nfrom ._shared import create_resource_and_send\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--page-size', type=int, dest='page_size')\nparser.add_argument('--properties')\nparser.add_argument('--max-items', type=int, dest='max_items')\nargs = parser.parse_args()\n\n_, resource = create_resource_and_send()\nparams = {}\nif args.page_size is not None: params['page_size'] = args.page_size\nif args.properties: params['properties'] = args.properties.split(',')\nif args.max_items is not None: params['max_items'] = args.max_items\nitems = resource['get_all'](**params)\nprint(json.dumps(items))\nprint(json.dumps({ 'rows_read': len(items) }))\n"
                            },
                            {
                              "type": "file",
                              "name": "sync_initial.py",
                              "template": "import argparse, json, time\nfrom ._shared import create_resource_and_send\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--page-size', type=int, dest='page_size')\nparser.add_argument('--properties')\nargs = parser.parse_args()\n\nstart = time.time()\n_, resource = create_resource_and_send()\nparams = {}\nif args.page_size is not None: params['page_size'] = args.page_size\nif args.properties: params['properties'] = args.properties.split(',')\ncount = 0\nfor item in resource['stream_all'](**params):\n    print(json.dumps(item))\n    count += 1\nprint(json.dumps({ 'rows_read': count, 'duration_seconds': time.time() - start }))\n"
                            },
                            {
                              "type": "file",
                              "name": "sync_incremental.py",
                              "template": "import argparse, json, time\nfrom datetime import datetime\nfrom ._shared import create_resource_and_send\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--cursor', required=True)\nparser.add_argument('--cursor-field', default='updated_at')\nparser.add_argument('--page-size', type=int, dest='page_size')\nparser.add_argument('--properties')\nargs = parser.parse_args()\n\nstart = time.time()\n_, resource = create_resource_and_send()\n\ncur = args.cursor\nfield = args.cursor_field\ncount = 0\n\n# str comparison fallback if not parseable as datetime\n\ndef is_gt(a: str, b: str) -> bool:\n    try:\n        return datetime.fromisoformat(a.replace('Z','+00:00')) > datetime.fromisoformat(b.replace('Z','+00:00'))\n    except Exception:\n        return a > b\n\nparams = {}\nif args.page_size is not None: params['page_size'] = args.page_size\nif args.properties: params['properties'] = args.properties.split(',')\nfor item in resource['stream_all'](**params):\n    val = item.get(field) if isinstance(item, dict) else None\n    if val is not None and is_gt(str(val), cur):\n        print(json.dumps(item))\n        count += 1\nprint(json.dumps({ 'rows_read': count, 'duration_seconds': time.time() - start }))\n"
                            },
                            {
                              "type": "file",
                              "name": "verify_webhook.py",
                              "template": "import argparse, hashlib, hmac, json, sys\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--secret', required=True)\nparser.add_argument('--signature', required=True)\nparser.add_argument('--payload-file')\nparser.add_argument('--algo', default='sha256')\nargs = parser.parse_args()\n\nif args.payload_file:\n    with open(args.payload_file, 'rb') as f:\n        payload = f.read()\nelse:\n    payload = sys.stdin.buffer.read()\n\ndigest = hmac.new(args.secret.encode('utf-8'), payload, getattr(hashlib, args.algo)).hexdigest()\nok = digest == args.signature or f'sha256={digest}' == args.signature\nprint(json.dumps({ 'ok': ok }))\nif not ok:\n    raise SystemExit(1)\n"
                            }
                          ]
                        },
                        {
                          "type": "dir",
                          "name": "tests",
                          "children": [
                            {
                              "type": "file",
                              "name": "test_client.py",
                              "template": "def test_ping():\n    from {packageName}.client import Client\n    assert Client({}).ping() is True\n"
                            }
                          ]
                        },
                        {
                          "type": "dir",
                          "name": "examples",
                          "children": [
                            {
                              "type": "file",
                              "name": "basic_usage.py",
                              "template": "from {packageName}.client import Client\n\nclient = Client({})\nprint(client.ping())\n"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}
